{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TruyenKieu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MRj1nhPkdBfOTl-MmlyplYgARG1eqO2I",
      "authorship_tag": "ABX9TyNmT+6NomKJiZKcFnuehL7K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ducviet00/Generating-TruyenKieu-Style/blob/master/TruyenKieu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWlSfRWYXE0S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "1d1be0ba-fa94-4ca9-ff38-784310b9317a"
      },
      "source": [
        "!pip install underthesea"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting underthesea\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/e8/832becde9ee2b14f81620e11e6417a882184756bdadc4399f096a9b6c94c/underthesea-1.1.17-py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 5.9MB/s \n",
            "\u001b[?25hCollecting languageflow==1.1.13a1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/be/62db3c61f872bbdd7d18671442601e6f59c4fb8004d73a03162f5b2bcc02/languageflow-1.1.13a1-py2.py3-none-any.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (7.1.2)\n",
            "Collecting python-crfsuite==0.9.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 50.8MB/s \n",
            "\u001b[?25hCollecting nltk<3.5,>=3.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 54.3MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.20.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/82/c0de5839d613b82bddd088599ac0bbfbbbcbd8ca470680658352d2c435bd/scikit_learn-0.20.3-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
            "\u001b[K     |████████████████████████████████| 5.4MB 22.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from languageflow==1.1.13a1->underthesea) (0.8.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from languageflow==1.1.13a1->underthesea) (2.23.0)\n",
            "Collecting joblib==0.13.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 58.4MB/s \n",
            "\u001b[?25hCollecting clint\n",
            "  Downloading https://files.pythonhosted.org/packages/3d/b4/41ecb1516f1ba728f39ee7062b9dac1352d39823f513bb6f9e8aeb86e26d/clint-0.5.1.tar.gz\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from languageflow==1.1.13a1->underthesea) (4.38.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk<3.5,>=3.4->underthesea) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.3->languageflow==1.1.13a1->underthesea) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.3->languageflow==1.1.13a1->underthesea) (1.18.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->languageflow==1.1.13a1->underthesea) (2.9)\n",
            "Collecting args\n",
            "  Downloading https://files.pythonhosted.org/packages/e5/1c/b701b3f4bd8d3667df8342f311b3efaeab86078a840fb826bd204118cc6b/args-0.1.0.tar.gz\n",
            "Building wheels for collected packages: nltk, clint, args\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449907 sha256=e1f5ae50865221b5664799e8e1c8af76e5ed1dc6771f47a61c37ede592f9ecfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for clint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clint: filename=clint-0.5.1-cp36-none-any.whl size=34449 sha256=c8d1c3aeaf429b9fd7b26d84505be0d606301dd9899b02a88f33ec66d33c5504\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/e9/45/223565e5b1a4b09e12c6de6f8ba7c2c0e9127dec17cf830f83\n",
            "  Building wheel for args (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for args: filename=args-0.1.0-cp36-none-any.whl size=3320 sha256=6a4acf210086ecb3edcdc79c924606b4475955d7573b878fafdd75fda9321793\n",
            "  Stored in directory: /root/.cache/pip/wheels/58/54/ea/d995d18af68c057eb76b87b02c92bc66ac34d360ef141780f4\n",
            "Successfully built nltk clint args\n",
            "Installing collected packages: scikit-learn, joblib, args, clint, languageflow, python-crfsuite, nltk, underthesea\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: joblib 0.14.1\n",
            "    Uninstalling joblib-0.14.1:\n",
            "      Successfully uninstalled joblib-0.14.1\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed args-0.1.0 clint-0.5.1 joblib-0.13.2 languageflow-1.1.13a1 nltk-3.4.5 python-crfsuite-0.9.6 scikit-learn-0.20.3 underthesea-1.1.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CzOeDNJdiAw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0cd0344-a156-4e9f-8ba0-d6bbe69778c7"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras import utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ6CTAV5y_Nm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.optimizers import RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4v8T0NpXZn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from underthesea import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anhu7LoJWfOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP5L3PlPXNvJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "3ab9b4a5-5663-47cc-8c7c-1c1a2a740274"
      },
      "source": [
        "path = '/content/drive/My Drive/Colab Notebooks/TruyenKieu/truyen_kieu_data.txt'\n",
        "df = pd.read_csv(path, sep=\"/\", names=[\"row\"], encoding=\"utf8\").dropna()\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1..Trăm năm trong cõi người ta,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2..Chữ tài chữ mệnh khéo là ghét nhau.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3..Trải qua một cuộc bể dâu,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4..Những điều trông thấy mà đau đớn lòng.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.. Lạ gì bỉ sắc tư phong,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6..Trời xanh quen thói má hồng đánh ghen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7..Cảo thơm lần giở trước đèn,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8..Phong tình có lục còn truyền sử xanh.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9,,Rằng năm Gia Tĩnh triều Minh,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.. Bốn phương phẳng lặng, hai kinh vững vàng.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               row\n",
              "0                  1..Trăm năm trong cõi người ta,\n",
              "1           2..Chữ tài chữ mệnh khéo là ghét nhau.\n",
              "2                     3..Trải qua một cuộc bể dâu,\n",
              "3        4..Những điều trông thấy mà đau đớn lòng.\n",
              "4                       5.. Lạ gì bỉ sắc tư phong,\n",
              "5        6..Trời xanh quen thói má hồng đánh ghen.\n",
              "6                   7..Cảo thơm lần giở trước đèn,\n",
              "7         8..Phong tình có lục còn truyền sử xanh.\n",
              "8                 9,,Rằng năm Gia Tĩnh triều Minh,\n",
              "9  10.. Bốn phương phẳng lặng, hai kinh vững vàng."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zC-57u6pYVEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transfrom(row):\n",
        "    s = []\n",
        "    punctuation = ['.', ',', '\\\"', '\\'', '?', ':', '!', '-', ';']\n",
        "    for i in row:\n",
        "        i = i.lower()\n",
        "        i = re.sub(r\"^[0-9\\., ]+\", \"\", i)\n",
        "        i = re.sub(r\"[\\.,\\?]+$\", \"\", i)\n",
        "        for p in punctuation:\n",
        "            i = i.replace(p, ' ')\n",
        "        s.append(i)\n",
        "    return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0zilntcaKse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = transfrom(df[\"row\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkTGJ9G7aeMq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "9a24dec8-af45-4b79-b962-351d682f0a10"
      },
      "source": [
        "corpus[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trăm năm trong cõi người ta',\n",
              " 'chữ tài chữ mệnh khéo là ghét nhau',\n",
              " 'trải qua một cuộc bể dâu',\n",
              " 'những điều trông thấy mà đau đớn lòng',\n",
              " 'lạ gì bỉ sắc tư phong',\n",
              " 'trời xanh quen thói má hồng đánh ghen',\n",
              " 'cảo thơm lần giở trước đèn',\n",
              " 'phong tình có lục còn truyền sử xanh',\n",
              " 'rằng năm gia tĩnh triều minh',\n",
              " 'bốn phương phẳng lặng  hai kinh vững vàng',\n",
              " 'có nhà viên ngoại họ vương',\n",
              " 'gia tư nghĩ cũng thường thường bực trung',\n",
              " 'một trai con thứ rốt lòng',\n",
              " 'vương quan là chữ  nối dòng nho gia',\n",
              " 'đầu lòng hai ả tố nga',\n",
              " 'thúy kiều là chị  em là thúy vân',\n",
              " 'mai cốt cách  tuyết tinh thần',\n",
              " 'một người một vẻ  mười phân vẹn mười',\n",
              " 'vân xem trang trọng khác vời',\n",
              " 'khuôn trăng đầy đặn  nét ngài nở nang']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UEHnq1bYufz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "01112f5b-8e79-42d1-c47a-b0d51805b364"
      },
      "source": [
        "i = word_tokenize(corpus[9])\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bốn phương', 'phẳng lặng', 'hai', 'kinh', 'vững vàng']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a72tkg5PYD_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_seg(corpus):\n",
        "    c = []\n",
        "    for i in corpus:\n",
        "        sentence = word_tokenize(i)\n",
        "        for j in sentence:\n",
        "            c.append(j)\n",
        "        c.append('\\n')\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2MFECRfZiTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = word_seg(corpus=corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ag7l6hT2bY5i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c09d8f42-3e34-4967-8664-2c46e4a7c15e"
      },
      "source": [
        "len(context)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22703"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfpCXrXXcXKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "def word2index(context):\n",
        "    word_counter = collections.Counter(context).most_common()\n",
        "\n",
        "    word2idx = dict()\n",
        "    idx2word = dict()\n",
        "\n",
        "    for word,i in word_counter:\n",
        "        index = len(word2idx)\n",
        "        word2idx[word] = index\n",
        "        idx2word[index] = word\n",
        "    \n",
        "    vocab_size = len(word2idx)\n",
        "\n",
        "    return word2idx, idx2word, vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAqFn2uAubWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx, idx2word, vocab_size = word2index(context)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-GvBQefvEeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2i_seq = [word2idx[word] for word in context]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PyvAIT2vPtN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "06195e0a-733f-42b4-e9d7-381d8ba4d477"
      },
      "source": [
        "print('The first ten words: ', context[:10])\n",
        "print('The corresponding int sequence: ', w2i_seq[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first ten words:  ['trăm', 'năm', 'trong', 'cõi', 'người ta', '\\n', 'chữ', 'tài', 'chữ', 'mệnh']\n",
            "The corresponding int sequence:  [103, 62, 18, 471, 472, 0, 125, 185, 125, 1192]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVMQFe9ZumXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc4b02cf-2954-4ab4-cb1c-20ddc1eeb657"
      },
      "source": [
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TstLcUJu9Jj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ceb88b05-4aa5-4fdc-d754-a235efe8a759"
      },
      "source": [
        "seq_length = 29\n",
        "\n",
        "x = list()\n",
        "y = list()\n",
        "\n",
        "for i in range(seq_length, len(w2i_seq)):\n",
        "    seq = w2i_seq[i-seq_length: i]\n",
        "    x.append(seq)\n",
        "    y.append(w2i_seq[i])\n",
        "\n",
        "x = np.array(x)\n",
        "\n",
        "y = utils.to_categorical(y, num_classes=vocab_size)\n",
        "\n",
        "print('Shape of inputSequences: ', x.shape)\n",
        "print('Shape of outputs: ', y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of inputSequences:  (22680, 29)\n",
            "Shape of outputs:  (22680, 3922)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHVVYWDjw8Dl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim=300\n",
        "lstm1_unit=64\n",
        "lstm2_unit=128\n",
        "hidden=128\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length))\n",
        "\n",
        "model.add(LSTM(units=lstm1_unit, return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=lstm2_unit))\n",
        "\n",
        "model.add(Dense(hidden, activation='relu'))\n",
        "\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7VllJKyXK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a62870f3-6d3e-468c-a811-93dfabe08685"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 29, 300)           1176600   \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 29, 64)            93440     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3922)              505938    \n",
            "=================================================================\n",
            "Total params: 1,891,306\n",
            "Trainable params: 1,891,306\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khJqiQFDya0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=RMSprop(lr=0.001, clipvalue=0.5), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3yZj9Y5zKT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_End4ysV2u5Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"/content/drive/My Drive/Colab Notebooks/TruyenKieu/model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYyCf5iONC3k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8d40e3e8-5de7-44b6-dccb-ecc4af1f8275"
      },
      "source": [
        "del model\n",
        "from keras.models import load_model\n",
        "model = load_model(\"/content/drive/My Drive/Colab Notebooks/TruyenKieu/model.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmVGrfUl2h2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test = x[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tRx7qNQzxqe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_words = [idx2word[index] for index in input_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxiMDwc-6FGb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(50):\n",
        "    pred = model.predict_classes(input_test.reshape((1,seq_length)), verbose=0)\n",
        "\n",
        "    input_test = np.append(input_test, pred[0])\n",
        "    input_test = input_test[1:]\n",
        "\n",
        "    predicted_words.append(idx2word[pred[0]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XACow9Dn6Hwr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a738ebaf-013a-4d15-98af-dc9fd85419bf"
      },
      "source": [
        "print('\\nThe words sequence generated by the Model: ')\n",
        "print(' '.join(predicted_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The words sequence generated by the Model: \n",
            "trăm năm trong cõi người ta \n",
            " chữ tài chữ mệnh khéo là ghét nhau \n",
            " trải qua một cuộc bể dâu \n",
            " những điều trông thấy mà đau đớn lòng \n",
            " lạ gì bỉ sắc tư phong \n",
            " trời xanh quen thói má hồng đánh ghen \n",
            " cảo thơm lần giở trước đèn \n",
            " phong tình có lục còn truyền sử xanh \n",
            " rằng năm gia tĩnh triều minh \n",
            " bốn phương phẳng lặng hai kinh vững vàng \n",
            " có nhà viên ngoại họ vương \n",
            " gia tư nghĩ cũng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ71D6ST4HPz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9f3d8bbc-ec80-4d74-bcd2-862f17fc09de"
      },
      "source": [
        "print(' '.join(context[:100]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trăm năm trong cõi người ta \n",
            " chữ tài chữ mệnh khéo là ghét nhau \n",
            " trải qua một cuộc bể dâu \n",
            " những điều trông thấy mà đau đớn lòng \n",
            " lạ gì bỉ sắc tư phong \n",
            " trời xanh quen thói má hồng đánh ghen \n",
            " cảo thơm lần giở trước đèn \n",
            " phong tình có lục còn truyền sử xanh \n",
            " rằng năm gia tĩnh triều minh \n",
            " bốn phương phẳng lặng hai kinh vững vàng \n",
            " có nhà viên ngoại họ vương \n",
            " gia tư nghĩ cũng thường thường bực trung \n",
            " một trai con thứ rốt lòng \n",
            " vương quan là chữ nối dòng nho gia \n",
            " đầu lòng hai ả tố nga\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}